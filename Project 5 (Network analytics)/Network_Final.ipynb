{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis on Stack Overflow website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Stack Overflow is a community based website that provides programmers and developers a platform to share professional knowledge. Via interactions like posting and answering questions, commenting, and etc., users participate in different topics and tend to form interests and, as a result, communities. \n",
    "\n",
    "This project aims to analyse the reason why users in Stack Overflow participate in certain threads. Having a deeper insight into how links formed among users and communities during time is helpful to handle possible business problems emerged in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Source\n",
    "The data used for the network analysis of Stack Overflow was acquired from the SNAP dump (https://snap.stanford.edu/data/sx-stackoverflow.html). \n",
    "SNAP dump consists of three different types of interactions: \n",
    "\n",
    "   + Answers to questions dataset (sx-stackoverflow-a2q);\n",
    "   \n",
    "   + Comments to questions dataset (sx-stackoverflow-c2q);\n",
    "   \n",
    "   + Comments to answers dataset (sx-stackoverflow-c2a).\n",
    "   \n",
    "Each dataset contains three columns:\n",
    "\n",
    "   + ID of the source node;\n",
    "\n",
    "   + ID of the target node;\n",
    "   \n",
    "   + Unix timestamp.\n",
    "\n",
    "Overall, Stack Overflow website can be divided into two different spaces (Figure 2.1):\n",
    "\n",
    "   + Question space. In this space users interact with each other by posting and answering questions. The link between users appear when one user answers to another user who posted the question. Answers to questions dataset was used to build the network on that space. \n",
    "\n",
    "   + Social space. In this space users interact with each other by commenting on each other's answers and questions. The link between users appear when one user comments another user’s answer or question. Comments to questions and Comments to answers datasets were taken to create the network on social space.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Idea Generation \n",
    "\n",
    "The main goal in network analysis of Stack Overflow is to investigate the reason why users participate in particular threads and why users can change their communities. \n",
    "\n",
    "It goes without saying that users participate in particular threads because of their interest in particular topics. Over time, users’ interest can change for various reasons, one of which is the influence of social space. Very often, starting the communication with several members from another threads and then increasing the number of these members can lead a user to change his previous thread into new one.\n",
    "\n",
    "Therefore, the goal of the project can be reformulated as follows: **Can the change in social space cause the change in question space?**\n",
    "\n",
    "The whole solution to the question can be divided into three parts:\n",
    "\n",
    "1. Analysis of the question space: community detection (4 paragraph);\n",
    "\n",
    "2. Analysis of the social space: triadic closures (6 and 7 paragraphs);\n",
    "\n",
    "3. Linkage between question and social space: membership closures (6 and 8 paragraphs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Community Detection Methods\n",
    "When trying to analyse social networks, the first step is to detect the communities. Community detection mechanism took place in question space.\n",
    "\n",
    "A community is “a group of nodes that have a higher likelihood of connecting to each other than to nodes from other communities” (Barabási, A., 2015). There have been various methods used to detect these existing communities.\n",
    "\n",
    "To conduct network analysis two algorithms were taken into consideration:\n",
    "\n",
    "1. The Girvan-Newman algorithm was constructed by Michelle Girvan and Mark Newman. The algorithm consists of two steps, Defining Centrality, and Hierarchical Clustering. \n",
    "\n",
    "+ The first step includes the definition and measuring of centrality. The algorithm needs a low centrality measure for the nodes within the same community and high measure for nodes located in different communities. To gather these measurements, the algorithm uses Link Betweenness and Random-Walk Betweenness. Link betweenness captures looks at the “role of each link in information transfer”(Barabási, A., 2015). \n",
    "\n",
    "+ The second step of the Girvan-Newman algorithm is the use of Hierarchical Clustering where the centrality of each link is computed, the link of the largest centrality is removed, and centrality of each link is recalculated.\n",
    "\n",
    "2. The Louvain algorithm is an algorithm that has been helpful in community detection. It is a method that is accurate due to the fact that it focuses on networks that are located within known community structures. There are two steps to implementing the algorithm, which are repeated until the required modularity is achieved.\n",
    "\n",
    "+ The first step includes the search for small or minute communities through the optimization of modularity in a local way.\n",
    "\n",
    "+ The second step of the algorithm is the aggregation of nodes within the same community. \n",
    "\n",
    "Due to fairly large analysed network size, the choice of the community detection method was made in favour of Louvain Algorithm because  it allows to identify communities in networks with millions of nodes in a relatively short period of time in comparison to Girvan-Newman algorithm.\n",
    "\n",
    "After applying Louvain Community Detection Algorithm, the list of nodes that changed their communities was found. Focusing only on that list, the analysis moved to the social space, where then only changes of that nodes were investigated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Louvain (graph):\n",
    "    partition_louvain = community.best_partition(graph)\n",
    "    size = float(len(set(partition_louvain.values())))\n",
    "    communities_louvain = []\n",
    "    for com in set(partition_louvain.values()):\n",
    "        list_nodes = [nodes for nodes in partition_louvain.keys() if partition_louvain[nodes] == com]\n",
    "        communities_louvain.append(list_nodes)\n",
    "    return communities_louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictneighb (communities):\n",
    "    neighb = []\n",
    "    for com in communities:\n",
    "        for node in com:\n",
    "            dct = {}\n",
    "            lst = [nd for nd in com if nd != node]\n",
    "            dct[node] = lst\n",
    "            neighb.append(dct)\n",
    "    return neighb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_diff (commOne, commTwo):\n",
    "    difference = []\n",
    "    for i in commTwo:\n",
    "        dct = {}\n",
    "        for j in commOne:\n",
    "            node_one = list(i.keys())[0]\n",
    "            node_zero = list(j.keys())[0]\n",
    "            if(node_one == node_zero):\n",
    "                values_zero = list(j.values())[0]\n",
    "                values_one = list(i.values())[0]\n",
    "                #if no intersection -> new community\n",
    "                #two_communities = []\n",
    "                if(bool(set(values_one).intersection(values_zero)) == False):\n",
    "                    #two_communities.append(values_zero)\n",
    "                    #two_communities.append(values_one)\n",
    "                    dct[node_one] = values_one\n",
    "                    difference.append(dct)\n",
    "    return difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preparation\n",
    "\n",
    "Data Preparation can be divided into the following steps:\n",
    "\n",
    "1. Transform Unix timestamp data in timedelta object and extract months from that object (function timedelta()).\n",
    "\n",
    "2. Concatenate Comment to question and Comment to answer datasets in order to build the network in social space.\n",
    "\n",
    "3. Filter the data for Question and Social space by month column in order to analyse first 15-month time period (t0 = 14, t1 = 15).\n",
    "\n",
    "4. Remove self-interactions for both Question and Social space (function removeSelfInter()).\n",
    "\n",
    "5. Leave only needed columns for future analysis (src_id and tgt_id). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSelfInter (df):\n",
    "    return df[df['src'] != df['tgt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('sx-stackoverflow-a2q.txt.gz',\n",
    "                   sep=' ',\n",
    "                   header=None,\n",
    "                   names=['src', 'tgt', 'ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the timespan for the analysis (in days)\n",
    "timespan = 30\n",
    "\n",
    "# time elapsed since the first email\n",
    "df.loc[:, 'td'] = pd.to_timedelta(df['ts'], unit='s')\n",
    "df.loc[:, 'm'] = df['td'].dt.days // timespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['m'] = df['m'] - min(df['m'])\n",
    "df.drop(['ts','td'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_14 = df.loc[df['m'] < 15, ['src','tgt']]\n",
    "df_15 = df.loc[df['m'] < 16, ['src','tgt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete those users who answered on their own question by themselves\n",
    "df_14 = removeSelfInter(df_14)\n",
    "df_15 = removeSelfInter(df_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_14 = nx.from_pandas_edgelist(df_14, source='src', target='tgt')\n",
    "G_15 = nx.from_pandas_edgelist(df_15, source='src', target='tgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_14 = Louvain(G_14)\n",
    "communities_15 = Louvain(G_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighb_14 = dictneighb(communities_14)\n",
    "neighb_15 = dictneighb(communities_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "difference_15 = community_diff (neighb_14, neighb_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_goers = []\n",
    "for com in difference_15:\n",
    "    nodes_goers.append(list(com.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "goers_size = len(nodes_goers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ComtoAns = pd.read_table('sx-stackoverflow-c2a.txt.gz',\n",
    "                   sep=' ',\n",
    "                   header=None,\n",
    "                   names=['src', 'tgt', 'ts']) \n",
    "               \n",
    "ComtoQue = pd.read_table('sx-stackoverflow-c2q.txt.gz',\n",
    "                   sep=' ',\n",
    "                   header=None,\n",
    "                   names=['src', 'tgt', 'ts']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the timespan for the analysis (in days)\n",
    "timespan = 30\n",
    "\n",
    "# time elapsed since the first comment\n",
    "ComtoAns.loc[:, 'td'] = pd.to_timedelta(ComtoAns['ts'], unit='s') \n",
    "ComtoAns.loc[:, 'month'] = ComtoAns['td'].dt.days // timespan\n",
    "ComtoAns['month'] = ComtoAns['month'] - ComtoAns['month'].min()\n",
    "Compart1 = ComtoAns.loc[(ComtoAns['month'] < 16),['src', 'tgt','month']]\n",
    "\n",
    "\n",
    "ComtoQue.loc[:, 'td'] = pd.to_timedelta(ComtoQue['ts'], unit='s') \n",
    "ComtoQue.loc[:, 'month'] = ComtoQue['td'].dt.days // timespan\n",
    "ComtoQue['month'] = ComtoQue['month'] - ComtoQue['month'].min()\n",
    "Compart2 = ComtoQue.loc[(ComtoQue['month'] < 16),['src', 'tgt','month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comfull = pd.concat([Compart1,Compart2],axis=0)\n",
    "\n",
    "Compart1 = Comfull.loc[(Comfull['month'] < 15),['src', 'tgt', 'month']]\n",
    "Compart2 = Comfull.loc[(Comfull['month'] < 16) ,['src', 'tgt', 'month']]\n",
    "\n",
    "Compart1 = removeSelfInter(Compart1)\n",
    "Compart2 = removeSelfInter(Compart2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Closures \n",
    "\n",
    "Assumption that changes in social space will contribute to transformations in communities was made. Thus closures detection mechanism taking place in social space is of vital importance.\n",
    "\n",
    "Social scientists have continuously studied the links between human beings in various social settings. The use of closures has been used to explain the relationships between individuals and groups where resources and information are shared amongst people with strong relations. Scientists, such as Georg Simmel, have come up with various ideologies to explain social interactions between individuals. \n",
    "\n",
    "Simmel was the pioneer of the Triadic Closure. A triadic closure is the tie that occurs amongst three individuals. For example, if A-B has a relationship, and A-C has a relationship, then there is a high probability of B-C having a tie. The tie amongst these three different individuals creates what is known as a community. Simmel compared the strength of the triadic closure to that of a dyad, indicating that the removal of one individual in the closure will still lead to the existence of a tie or a community as there are two other members that are still aligned. The existence of closures are essential to understand social networks in society and can explain social interactions within communities. \n",
    "\n",
    "Another closure that has been frequently used in the study of social networks is membership closure. Membership closures occur when A is tied to a particular focus B, while there is a tie between A and C. The assumption is that due to the tie between A-C, C will be tied to the original focus B. The membership closure has been used to understand why individuals within the same group have similar interests in certain activities. \n",
    "\n",
    "The probability of appearance of the membership closure is exactly the probability of community changes. \n",
    "\n",
    "Therefore, the goal again can be reformulated as follows: **What is the probability of the community change according to different scenarios and factors?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_links (node, period):\n",
    "    if(period == 0):\n",
    "        neighb_src = list(Compart1.loc[(Compart1['src'] == node),'tgt'].values)\n",
    "        neighb_tgt = list(Compart1.loc[(Compart1['tgt'] == node),'src'].values)\n",
    "        neighb = neighb_src + neighb_tgt\n",
    "    else:\n",
    "        neighb_src = list(Compart2.loc[(Compart2['src'] == node),'tgt'].values)\n",
    "        neighb_tgt = list(Compart2.loc[(Compart2['tgt'] == node),'src'].values)\n",
    "        neighb = neighb_src + neighb_tgt\n",
    "    return neighb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Degrees\n",
    "\n",
    "From the described above triadic closures, it can be concluded that if a user A formed a connection with a user B from another community who have a considered amount of neighbours from his community, the number of probable triadic closures will increase, which means that user A will have even more links with another community and highly likely will move to that community. \n",
    "\n",
    "The node degree is used to show how well connected a node is within its community. That is why, it was decided to take a look at nodes degrees and see what impact this factor can have. \n",
    "\n",
    "For the description of the idea with nodes degrees, suppose that in t0 period, node A was in community C0, while in t1 period node A moved to community C1.\n",
    "\n",
    "The analysis based on degrees is:\n",
    "\n",
    "1. Calculate the degree of nodes in community C1 that connected with A\n",
    "\n",
    "2. Get the sum of degrees, that under considered assumption will have a possible impact on A’s movement from C0 to C1. \n",
    "\n",
    "3. Set the mean of maximum and minimum degree in the community as the boundary value.\n",
    "\n",
    "4. Compare the degree value received in step 2 with the boundary value, to decide whether nodes are strong or weak connected to the community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for com in communities_15:       \n",
    "    degrees = []\n",
    "    node_degrees = {}\n",
    "    for node in com:\n",
    "        properties = []\n",
    "        node_neighbours = list(dict(G_15[node]).keys())\n",
    "        node_degree = len(set(com).intersection(node_neighbours))\n",
    "        properties.append(node_degree)\n",
    "        node_degrees[node] = properties\n",
    "        degrees.append(node_degree)\n",
    "    max_degree = max(degrees)\n",
    "    min_degree = min(degrees)\n",
    "    boundaries_value = int((max_degree+min_degree)/2)\n",
    "    for key in list(node_degrees.keys()):\n",
    "        if (node_degrees[key][0]<boundaries_value):\n",
    "            properties = list(node_degrees[key])\n",
    "            properties.append('weak')\n",
    "            properties.append(boundaries_value)\n",
    "            node_degrees[key] = properties\n",
    "        else:\n",
    "            properties = list(node_degrees[key])\n",
    "            properties.append('strong')\n",
    "            properties.append(boundaries_value)\n",
    "            node_degrees[key] = properties\n",
    "    result.append(node_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_class = dict()\n",
    "for com in result:\n",
    "    degrees_class.update(com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Probabilities \n",
    "\n",
    "The final step is to calculate the probability for nodes to change their communities based on different scenarios in social space in t0 and t1 periods.\n",
    "\n",
    "To simplify complex problem, all possible scenarios for t0 period were divided into two big cases:\n",
    "\n",
    "1. There were no nodes in C1 connected to A in t0 period.\n",
    "\n",
    "2. There were some links (without knowing the exact number) between A and nodes in C1 in t0.\n",
    "\n",
    "Each of these two scenarios has two subcases in t1 period: \n",
    "\n",
    "1. Node A formed only one new link in C1\n",
    "\n",
    "2. Node A formed more than one new links, regardless of the precise number, in t1 period. \n",
    "\n",
    "In their turn, these two subcases are considered under degree computation that separates weak and strong connections in two different possibilities. \n",
    "\n",
    "Eventually, eight separate cases in total were taken into consideration.\n",
    "\n",
    "Probability is calculated by the number of eligible for each cases nodes divided by the total number of nodes that change communities. \n",
    "\n",
    "As a result, eight probabilities that represent eight cases were calculated.\n",
    " \n",
    "With probabilities there is an ability to get some insights of how degrees, the number of former links and the number of newly appeared links influence certain nodes to change their communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "option01_weak = 0\n",
    "option01_strong = 0\n",
    "option02_weak = 0\n",
    "option02_strong = 0\n",
    "option11_weak = 0\n",
    "option11_strong = 0\n",
    "option12_weak = 0\n",
    "option12_strong = 0\n",
    "for diff in difference_15:\n",
    "    node_goer = list(diff.keys())[0] \n",
    "    node_goer_values = list(diff.values())[0]\n",
    "    neighb_zero = find_links(node_goer,0)\n",
    "    neighb_one = find_links(node_goer,1)\n",
    "    if(len(neighb_zero) != 0 | len(neighb_one) != 0):\n",
    "        #intersection with community in t0\n",
    "        intersect_zero_com = set(neighb_zero).intersection(node_goer_values)\n",
    "        intersection = set(neighb_one).intersection(node_goer_values)\n",
    "        intersect_elemnum = len (intersection)\n",
    "        #if there is no intersections between t0 and nodes from community\n",
    "        if(bool(intersect_zero_com) == False):\n",
    "            #find the intersection between t1 and nodes from community (how many links were formed:\n",
    "            # we are interested in one and more than one formed links)\n",
    "            if(intersect_elemnum == 1):\n",
    "                intersect_elem = list(intersection)[0]\n",
    "                if(degrees_class[intersect_elem][1] == 'weak'):\n",
    "                    option01_weak = option01_weak + 1\n",
    "                    #one new link with weak member\n",
    "                else:\n",
    "                    option01_strong = option01_strong + 1\n",
    "                    #'one new link with strong member'\n",
    "            if(intersect_elemnum > 1):\n",
    "                intersect_elem = list(intersection)\n",
    "                degrees = [degrees_class[element][0] for element in intersect_elem]\n",
    "                summa = sum(degrees)\n",
    "                if(summa < degrees_class[intersect_elem[0]][2]):\n",
    "                    #several new links and weak connectivity\n",
    "                    option02_weak = option02_weak + 1\n",
    "                else:\n",
    "                    #several new links and strong connectivity\n",
    "                    option02_strong = option02_strong + 1\n",
    "        #if there is intersections between t0 and nodes from community\n",
    "        else:\n",
    "            if (intersect_elemnum == 1):\n",
    "                intersect_elem = list(intersection)[0]\n",
    "                if(degrees_class[intersect_elem][1] == 'weak'):\n",
    "                    #already existed several links; new formed link and weak connectivity\n",
    "                    option11_weak = option11_weak + 1\n",
    "                else:\n",
    "                    #already existed several links; new formed link and strong connectivity\n",
    "                    option11_strong = option11_strong + 1   \n",
    "            if(intersect_elemnum > 1):\n",
    "                #intersection with community in t1\n",
    "                intersect_zero = list(intersect_zero_com)\n",
    "                intersect_elem = list(intersection)\n",
    "                degrees_t0 = [degrees_class[element][0] for element in intersect_zero]\n",
    "                degrees_t1 = [degrees_class[element][0] for element in intersect_elem]\n",
    "                summa = sum(degrees_t0)+sum(degrees_t1)\n",
    "                if (summa< degrees_class[intersect_elem[0]][2]):\n",
    "                    #already existed several links; several new formed link and weak connectivity\n",
    "                    option12_weak = option12_strong + 1\n",
    "                else:\n",
    "                    #already existed several links; new formed link and strong connectivity\n",
    "                    option12_weak = option12_strong + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_1 = option01_weak/goers_size\n",
    "probability_2 = option01_strong/goers_size\n",
    "probability_3 = option02_weak/goers_size\n",
    "probability_4 = option02_strong/goers_size\n",
    "probability_5 = option11_weak/goers_size\n",
    "probability_6 = option11_strong/goers_size\n",
    "probability_7 = option12_weak/goers_size\n",
    "probability_8 = option12_strong/goers_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.1282051282051282 0.0 0.02564102564102564 0.0 0.02564102564102564 0.02564102564102564 0.0\n"
     ]
    }
   ],
   "source": [
    "print(probability_1,probability_2,probability_3,probability_4,probability_5, probability_6, probability_7, probability_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Insights  \n",
    "\n",
    "From the received probabilities, it’s clearly seen that:\n",
    "\n",
    "1. If no links formed in t0 period, then:\n",
    "\n",
    "+ The more new links will be formed in t1, the higher will be the probability for a node to change its community. This can be explained by the fact that the more new neighbors from another community node will have, the higher will be the probability that this node’s interest will change to the interest of its new neighbors.  \n",
    "\n",
    "+ The more degree the nodes from community to which the link was formed have, the higher will be the probability of community change. The reason for these rises can be explained by the probable appearance of triadic closures within social space, which implies that the node is more likely to connect to other nodes within the community via triadic closures and therefore change its community.\n",
    "\n",
    "2.  If several links formed in t0 period, then the conclusion could be:\n",
    "\n",
    "+ The value of probability does not drop in comparison to the first case, because in t0 period there was an initial number of neighbors from community to which node jumped and then the number of neighbors becomes bigger in t1 period (see explanations in 1.1). At the same time, the value of probability is not higher than that from the first case, which can mean that the number of links that were formed in t0 period has not a significant impact on change in communities in comparison to the number of newly created links, number of links in total and nodes’ degree that have an effect. \n",
    "\n",
    "To sum up, the conclusion is that changes in social space indeed can be a reason why nodes tend to change their communities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Limitations and Further Research\n",
    "In network analysis of Stack Overflow there were few limitations that are listed below:\n",
    "\n",
    "1. The differences among probabilities get from the output are insignificant and some probabilities are equal to 0. The possible reason can be the fact of data. First 15 months were chosen for analysis when social exchanges just started and communities just appeared and there was no formed extensive interactions. Thereby, the number of nodes that changed their communities in considered time period is small, and even becomes smaller in social space because nodes that were active in question space might not participate in social space interactions.\n",
    "\n",
    "2. Limited power of server. Due to this limitation there was no possibility to conduct the analysis on later time period (with bigger volume of data) when the interactions between users both in social and question space become more developed.\n",
    "\n",
    "3. The reasons why users participate in certain threads must be more complex than that was explained in this work. It is impossible to consider all possible reasons, the number of which is significantly high, and interpret them well. Thus, the problem was simplified and considered under two base scenarios regardless of other possible cases (e.g. the impact of triadic closure in social space on community was not analysed in detail). \n",
    "\n",
    "For the future research, methods and algorithms used to analyse should be chosen carefully, taking into consideration not only speed but also accuracy and fitness. What’s more, influences of factors such as triadic closure and membership closure can be dug deeply with more sophisticated research plan.\n",
    "\n",
    "\n",
    "References\n",
    "==========\n",
    "1. Barabási, A. (2015). Network Science. Cambridge University Press,Chapter9.\n",
    "2. Easley, D. and Kleinberg, J. (2010). k Networks, Crowds, and Markets: Reasoning about a Highly Connected World. Cambridge University Press, pp.85-118.\n",
    "3. FindCommunities. [online] Available at: https://sites.google.com/site/findcommunities/ \n",
    "4. Simmel, G. (1950). The Sociology of Georg Simmel. New York City: Simon and Schuster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
